<!DOCTYPE html>
<html>

<head>
	<title>[High-performance computing (HPC)](/courses/#table-of-contents)</title>
	<meta charset="utf-8">
	<link rel="stylesheet" href="../remarkslides.css">
	<!-- MathJaxâ„¢ -->
	<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async>
	</script>
	<!-- mermaid dijagram -->
	<link rel="stylesheet2" href="../mermaid.min.css">
	<script>
		mermaid.initialize({startOnLoad:true});
	</script>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127734928-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		      function gtag(){dataLayer.push(arguments);}
		      gtag('js', new Date());
		
		      gtag('config', 'UA-127734928-1');
	</script>
	<!-- google analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		      ga('create', 'UA-127734928-1', 'auto');
		      ga('send', 'pageview');
	</script>
</head>

<body>
	<textarea id="source">class: center, middle

## [High-performance computing (HPC)](/courses/#table-of-contents)
### Arhitektura


.author[[dr. Milovan TomaÅ¡eviÄ‡](https://www.milovantomasevic.com/resume/)]

.small[[Fakulteta za informacijske Å¡tudije v Novem mestu (FIÅ )](https://www.fis.unm.si/en/)</br>![:scale 10%](../fis/fis.png) .small[ [ğŸŒâ™ milovan.tomasevic.fis.unm.si](http://milovan.tomasevic.fis.unm.si)</br> [ğŸ“§â™ milovan.tomasevic@fis.unm.si](mailto:milovan.tomasevic@fis.unm.si)]]



.created[08.03.2019 u 15:47]


---


class: center, middle, inverse

# Arhitektura superraÄunara

#### pregled moguÄ‡ih reÅ¡enja

---
layout: true

.section[[Arhitektura superraÄunara](#sadrzaj)]

---

## Veza sa drugim predmetima

- Mi ovo radimo tek ovlaÅ¡.
- Mnogo viÅ¡e o ovome radite kod prof. Å½ivanova
- BiÄ‡e neÅ¡to preklapanja izmeÄ‘u onoga Å¡to ja kaÅ¾em i onoga Å¡to on kaÅ¾e, ali generalno govoreÄ‡i od njega dobijate najbolje podatke.
- Svrha ovoga jeste da imamo reÄnik koji delimo da bi mogli da
priÄamo o tome Å¡ta programiramo.

---

## Faktori performanse HPC sistema

- Brzina komponenata
	- Koliko se brzo stvari deÅ¡avaju na individualnoj komponenti
- Paralelizam komponenata
	- Koliko stvari se izvrÅ¡ava jednovremeno
	- Koliko stvari se efektno paralelizuje
- Efikasnost komponenata
	- Koji procenat vremena je sistem sposoban da radi

---

## Faktori performanse HPC sistema

- P - performanse sistema kao apstrakcija
- e - efikasnost sistema
- S - faktor skaliranja
- a - funkcija dostupnosti
	- Äiji je parametar R-pouzdanost
- Âµ - stopa izvrÅ¡avanja instrukcija kao funkcija
	- Äiji je parametar E-snaga

---

## Faktori performanse HPC sistema

<p>

$$P=e Ã—SÃ—a(R)Ã—\mu(E)$$
  
</p>

- O efikasnosti
  - Efikasnost se lako definiÅ¡e: to je odnos ostvarenih i teoretskih performansi, tj.

<p>

$$e_{flops}=\frac{P_{kont}}{P_{max}}$$
  
</p>

---
## O pouzdanosti

- Sporiji algoritmi mogu da priuÅ¡te da budu provereni i sigurno taÄni
- Ali ako hoÄ‡emo brzinu greÅ¡ke su neminovne
- Sistemi su jednostavno previÅ¡e komplikovani

---

## U prolazu

>Å to viÅ¡e znam o kompjuterima, sve sam viÅ¡e iznenaÄ‘en kada rade.
<br>Nepoznati FTN student, hol fakulteta 2008

- Ovo tek vaÅ¾i za superraÄunare.
- Svi ti delovi, sve te komponente...
- Stvarno jeste Äudo Å¡to rade.

---

## Metodi pouzdanosti

- GreÅ¡ke nisu kraj sveta
- Pomislite na `TCP` vs. `UDP`
- Metod koji se koristi najÄeÅ¡Ä‡e je `checkpoint/restart`
- Å to da ne? 
- Sve Å¡to izgubimo je vreme.
- Ako je vreme koje gubimo na povremeni `restart` manje od vremena koje bi gubili na sporiji algoritam - pobeda!

---

## Flinova taksonomija

- Postoje mnogi naÄini da se opiÅ¡e arhitektura paralelnih sistema i mnogi naÄini da se takvi sistemi projektuju.
- Da bi mogli da priÄamo bez previÅ¡e mahanja rukama i objaÅ¡njavanja dobro je da imamo nekakve zajedniÄke termine
- Primer takvih zajedniÄkih termina jeste Flinova taksonomija, sistem denotiranja razliÄitih arhitektura koji je napravio Majkl Flin 70-tih kodina proÅ¡log veka.

---

## Faktori Flinove taksonomije

- Flinova taksonomija ima dve dimenzije po kojima varira-podaci i instrukcije, oznaÄene u sistemu kao D i I.
- I D i I dimenzije mogu da variraju izmeÄ‘u dve vrednosti: S (single) i M (multiple) po tome da li se u jednom trenutku u sistemu izvrÅ¡ava operacija nad viÅ¡e tokova podataka ili se izvrÅ¡ava viÅ¡e niti kontrole
- Kombinatorika nam, onda, daje `Ä‡oÅ¡kove` faznog prostora HPC arhitekture:
	- SISD
	- SIMD
	- MIMD
	- MISD

---

## SISD

- NajklasiÄnija Fon Nojmanova arhitektura
- Jedna stvar u jednom trenutku
- NiÅ¡ta danas ne radi ovako, praktiÄno
- No, i dalje je koristan mentalni model poÅ¡to vaÅ¡a userland aplikacija gotovo sigurno radi ovako.

---

## SIMD

- Uvek se radi ista stvar
- Ali se istovremeno radi na velikom skupu podataka
- Da bi to razumeli, hajde da razmiÅ¡ljamo o idealizovanoj grafiÄkoj kartici koja izvrÅ¡ava Fongov model senÄenja

<p>

$$I_{p}=k_{b}i_{a}+\sum_m(k_{d}(\widehat{L}_{m}\cdot\widehat{N})i_{m,d}+k_{s}(\widehat{R}_{m}\cdot\widehat{V})^{\alpha}i_{m,s}) \\   \quad m\in light$$
  
</p>

---

## SIMD

```java

// Vertex Shader Source Code 

varying vec3 N;
varying vec3 v;

void main(void)  
{     
   v = vec3(gl_ModelViewMatrix * gl_Vertex);       
   N = normalize(gl_NormalMatrix * gl_Normal);

   gl_Position = gl_ModelViewProjectionMatrix * gl_Vertex;  
}
          
```

---

## SIMD

.medium[
```java
// Fragment Shader Source Code 
varying vec3 vN;
varying vec3 v; 
#define MAX_LIGHTS 3 

void main (void) 
{ 
   vec3 N = normalize(vN);
   vec4 finalColor = vec4(0.0, 0.0, 0.0, 0.0);
   
   for (int i=0;i<MAX_LIGHTS;i++)
   {
      vec3 L = normalize(gl_LightSource[i].position.xyz - v); 
      vec3 E = normalize(-v); // we are in Eye Coordinates, so EyePos is (0,0,0) 
      vec3 R = normalize(-reflect(L,N)); 
   
      //calculate Ambient Term: 
      vec4 Iamb = gl_FrontLightProduct[i].ambient; 
      //calculate Diffuse Term: 
      vec4 Idiff = gl_FrontLightProduct[i].diffuse * max(dot(N,L), 0.0);
      Idiff = clamp(Idiff, 0.0, 1.0); 
      // calculate Specular Term:
      vec4 Ispec = gl_FrontLightProduct[i].specular * pow(max(dot(R,E),0.0),0.3*gl_FrontMaterial.shininess);
      Ispec = clamp(Ispec, 0.0, 1.0); 
      finalColor += Iamb + Idiff + Ispec;
   }
   // write Total Color: 
   gl_FragColor = gl_FrontLightModelProduct.sceneColor + finalColor; 
}         
```
]

---
## SIMD

![:scale 60%](img/simd.png)

.footer.medium[
  [Detaljnije](https://www.opengl.org/sdk/docs/tutorials/ClockworkCoders/lighting.php)

] 

---
## SPMD

- U praski ovo nije baÅ¡ SIMD.
- Nije paralelizam baÅ¡ u instrukcijama
- Ali jeste sluÄaj da imamo jedan program a viÅ¡e tokova podataka.
- Tako da je moderan GPU striktno govoreÄ‡i primer SPMD arhitekture.
- No, sa druge strane, SPMD je samo praktiÄna inkarnacija SIMD ideje.
- Ne treba se previÅ¡e drÅ¾ati Flinovih apstrakcija. One su divne da nam opiÅ¡u `Ä‡okove` prostora u kome obitavamo, ali kretanje po tom prostoru dozvoljava dosta varijacije.
- Moderan *heterogen sistem* je takav da ima zapanjujuÄ‡e mnogo gradacije izmeÄ‘u stepena deljene memorije, nivoa paralelizma, itd.

---

## Heterogen sistem?

- Koristimo taj termin relativno Äesto
- Programiranje u heterogenim sistemima Ä‡e biti naÅ¡ glavni izazov
- Pa Å¡ta je heterogen sistem?
- Neformalna definicija: 
    - Sistem koji meÅ¡a razne delove Flinove taksonomije u svojim razliÄitim delovima: hibrid raznih arhitektura i pristupa vo?en samo Å¾eljom za najviÅ¡e performansi.
- Heterogeni sistemi zvuÄe vrlo novo i uzbudljivo ali, istina je da su oni veÄ‡ duÅ¾e vremena sa nama i da vi verovatno imate jedan.
- LiÄni raÄunari su uvek bili heterogeni, a nikad viÅ¡e nego danas gde je razlika izmeÄ‘u superraÄunara i nekog gaming PC-ja uglavno stvar razmere ne prirode.

---

## SIMD nizovi

- SIMD niz (SIMD Array) je tehnika izrade superraÄunara koja je svoj vrhunac doÅ¾ivela u 80-tim i 90-tim godinama proÅ¡log veka.
- Ideja je da se raÄunar sastoji od jako mnogo prostih procesorskih elemenata kojima upravlja kontroler sekvence koji se stara da rade istu stvar u isto vreme
- Svaki takav element radi, onda, nad svojim komadom memorije uz minimalno povremeno komuniciranje sa memorijom drugih komada memorije.
- Ovo jako liÄi na fixed-pipeline arhitekturu grafiÄkih kartica ranijih generacija.

---

## Procena performansi i Amdalov zakon

- Amdalov zakon je metod da se proceni performansa paralelizovanog sistema
- TaÄnije reÄeno, Amdalov zakon povezuje stepen paralelizacije sa ostvarenim dobitkom u performansama.
- Ovo je teÅ¾ak problem, te je zakon samo pribliÅ¾ni model koji naroÄito odgovara baÅ¡ SIMD nizovima.

---
## Amdalov zakon

- Zamislim SIMD niz procesor koji ima dva reÅ¾ima izvrÅ¡avanja:
	- Sekvencijalni (gde izvrÅ¡ava funkciju po funkciju)
	- Paralelni (gde izvrÅ¡ava sa svim svojim PE-ovima)
- Neka je T0 ukupno vreme za neki prora?un
- A neka je TF vreme za sekvencijalno izvrÅ¡avanje operacija koje se mogu izvrÅ¡avati u paraleli, dok je TA vreme koje je zaista potrebno.
- Dalje, neka je g stepen paralizma, S stepen ubrzanja, a f proporcija operacija koje se mogu paralelizovati.
- Onda:

---

## Amdalov zakon

.small[
<p>

$$ Speedup_{parallel}(f,n)=\frac{1}{(1-f)+(\frac{f}{n})} \\ Speedup_{enhanced}(f,S)=\frac{1}{(1-f)+(\frac{f}{S})} $$
  
</p>
]

![:scale 60%](img/AmdahlsLaw.svg)

---

## MIMD

- Ovo je svet u kome mi, u stvari, Å¾ivimo
- No, ponekad, to se krije od nas
- NajÄistiji primer ovako neÄega jeste sistem Ävorova, gde je svaki Ävor procesor koji komunicira sa drugim Ävorovima preko mreÅ¾e
- ProveÅ¡Ä‡emo najviÅ¡e vremena u hibridnom `MIMD/SIMD` svetu.

---

## Multiprocesori

- PraktiÄno ovaploÄ‡enje `MIMD` pristupa.
- To je arhitektura modernih super-raÄunara. 
- Mnogo Ävorova, mnogo procesora.
- Multiprocesorske arhitekture imaju varijacije

---

## Multiprocesori deljene memorije

- Sistem gde imamo N procesora, deljenu magistralu, i jednu memoriju za sve.
- Idealno, ovo funkcioniÅ¡e kao UMA arhitektura - *uniform memory access*. 
- To znaÄi da bilo koji deo memorije je ne samo jednako dostupan bilo kom procesoru, nego je dostupan u jednakom vremenu.

---

## Multiprocesori deljene memorije

![:scale 85%](img/uma.gif)

---

## Problem keÅ¡a

- Koherentnost keÅ¡a je ogroman problem za ovakve arhitekture
- TipiÄno se koristi *Modified Exclusive Shared Invalid* protokol, tkzv. `MESI`.
- Poznat joÅ¡ i kao `njuÅ¡kalo keÅ¡` (*Snooping cache*)
- `UMA` je moguÄ‡a (donekle) na obiÄnom raÄunaru
- Ali danaÅ¡nje maÅ¡ine su skoro sve `NUMA`, tj. ne `UMA`: neka memorija je blizu a neka daleko. FiziÄki a i logiÄki.

---

## Masivno paralelni multiprocesori

- `MPM`-ovi nemaju deljenu memoriju nego `distribuiranu memoriju`.
- Striktno govoreÄ‡i (i u stilu toga Å¡to su nam sve oznake labave i predstavljaju samo proizvoljne linije povuÄene po kontinualnim skalama) model distribuirane memorije je samo ekstreman `NUMA` model.
- Kako?
- Pa Ävor ima svoju memoriju koja je `NUMA`-tiÄno manje-viÅ¡e deljena, ali je povezan sa svim drugim Ävorovima preko interfejsa za prosleÄ‘ivanje poruka koji, tehniÄki, omoguÄ‡ava pristup (iako jako spor i indirektan) svoj memoriji sistema.

---

## Kako to izgleda danas

![:scale 75%](img/cpu.png)

---

## PotroÅ¡aÄki klasteri

- PotroÅ¡aÄki klaster (*comodity cluster*) nije toliko posebna arhitektura koliko je specifiÄna implementacija masivno paralelne arhitekture.
- Ideja je da se `MPM` arhitektura implementira upotrebljavajuÄ‡i hardver koji je namenjen potroÅ¡aÄima
- ZaÅ¡to ovo radi?
	1. Ekonomije skale.
	2. Video igre.
- Naravno reÅ¡enje je manje efikasno: vrhunska `MPM` reÅ¡enja su skoro pa 90% efikasna na odabranim problemima.
- ÄŒak i najbolji potroÅ¡aÄki klasteri retko probijaju 60%.
- Ali su mnogo jeftiniji i ekonomski se skaliraju fantastiÄno.

---

## Internet-bazirani potroÅ¡a?ki klasteri

- Ekstreman primer ovoga jeste ideja da svako ko hoÄ‡e moÅ¾e da postane deo super-raÄunara koji reÅ¡ava neki ogroman problem.
- Folding@home, na primer.
- Ovo je sluÄaj gde je izolovanost Ävorova komiÄno velika, ali je to i dalje sasvim OK za odreÄ‘eni tip problema, uglavnom u kategoriji smeÅ¡no paralelnih (viÅ¡e o tome kasnije).
- NajuspeÅ¡niji primer je verovatno globalna bitcoin mreÅ¾a
	- Pet miliona triliona proraÄuna SHA256 vrednosti svakog sekunda.

---

## MISD

- Neki smatraju da je ovo besmislena kategorija
- Isti podaci a viÅ¡e tokova instrukcija?!
- Imaju dve klasiÄne interpretacije:
	- Coarse-grained pipeline
	- Deljena memorija
- Na jedan naÄin, moglo bi se reÄ‡i da Ä‡e OpenMP sa kojim se suoÄavate veÄeras primer MISD arhitekture.

--

class: center, middle, theend, hide-text
layout: false
background-image: url(../theend.gif)

</textarea>
	<script src="../remark-latest.min.js"></script>
	<script>
		// https://github.com/gnab/remark/issues/72
		        remark.macros.scale = function (percentage) {
		            var url = this;
		            return '<div class="center"><img src="'
		                 + url + '" style="width: ' + percentage + '" /></div>';
		        };
		        var slideshow = remark.create({
		                    highlightLanguage: 'python',
		                    // highlightStyle: 'obsidian',
		                    highlightStyle: 'github',
		                    highlightLines: true,
		                    countIncrementalSlides: false,
		                    navigation: {
		                      // Enable or disable navigating using scroll
		                      // Default: true
		                      // Alternatives: false
		                      scroll: false,
		
		                      //click: true,
		                    }
		                });
	</script>
	<script src="../mermaid.min.js"></script>
	<script>
		mermaid.initialize({startOnLoad:true});
	</script></body>

</html>