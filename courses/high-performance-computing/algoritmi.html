<!DOCTYPE html>
<html>

<head>
	<title>[High-performance computing (HPC)](/courses/#table-of-contents)</title>
	<meta charset="utf-8">
	<link rel="stylesheet" href="../remarkslides.css">
	<!-- MathJaxâ„¢ -->
	<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async>
	</script>
	<!-- mermaid dijagram -->
	<link rel="stylesheet2" href="../mermaid.min.css">
	<script>
		mermaid.initialize({startOnLoad:true});
	</script>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127734928-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		      function gtag(){dataLayer.push(arguments);}
		      gtag('js', new Date());
		
		      gtag('config', 'UA-127734928-1');
	</script>
	<!-- google analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		      ga('create', 'UA-127734928-1', 'auto');
		      ga('send', 'pageview');
	</script>
</head>

<body>
	<textarea id="source">class: center, middle

## [High-performance computing (HPC)](/courses/#table-of-contents)
### Algoritmi


.author[[dr. Milovan TomaÅ¡eviÄ‡](https://milovantomasevic.com/resume/)]

.small[[Fakulteta za informacijske Å¡tudije v Novem mestu (FIÅ )](https://www.fis.unm.si/en/)</br>![:scale 10%](../fis/fis.png) .small[ [ğŸŒâ™ milovan.tomasevic.fis.unm.si](http://milovan.tomasevic.fis.unm.si)</br> [ğŸ“§â™ milovan.tomasevic@fis.unm.si](mailto:milovan.tomasevic@fis.unm.si)]]



.created[08.03.2019 u 16:54]


---


class: center, middle, inverse

# Paralelni algoritmi
#### temelji paralelnog programiranja

---
layout: true

.section[[Paralelni algoritmi](#sadrzaj)]

---

## Objedinjenje

- Broj problema je manje-viÅ¡e neograniÄen.
- ReÅ¡enja, sa druge strane, Äesto imaju zajedniÄke osobine.
- Ove zajedniÄke osobine mogu da se iskoriste da formiraju grupe reÅ¡enja.
- Ovo je odliÄna olakÅ¡ica, poÅ¡to moramo da razumemo samo ograniÄen broj stvari da bi reÅ¡ili veliki broj problema.

---
## Digresijaâ€”uopÅ¡tavanje

- Ovo je namenjeno da vaÅ¾i samo za HPC i nauÄne proraÄune, ali, istinski, vaÅ¾i za skoro sve.
- NaroÄito zanimljivo jeste koliko dobro vaÅ¾i za matematiku.
- Biti spolja i gledajuÄ‡i unutra, ponekad se Äini da je matematika forma ÄarobnjaÅ¡tva gde ljudi inicirane u njene unutarnje misterije jednostavno znaju Å¡ta da urade kroz neobjaÅ¡njive gnostiÄke metode.
- Ovo, naravno, nije taÄno: proces je gotovo uvek pokazivanje homomorfizma izmeÄ‘u neÄega Å¡to znamo i neÄega Å¡to prouÄavamo i portovanje znanja iz prvog u drugi.
- Zanimljiv sajt koji pokuÅ¡ava da ilustruje univerzalne alate za ovako Å¡to je http://www.tricki.org/tricki/map
- Dobra knjiga na ovu temu je `Concrete Mathematics`

---
## Klase numeriÄkih metoda

- HPC je gotovo uvek namenjen raznim numeriÄkim metodama.
- NumeriÄke metode su, jednostavno reÄeno, mehanizmi za reÅ¡avanje matematiÄkih problema kroz mehaniÄke metode.
- MoÅ¾da se naleteli na termin kroz `numeriÄku analizu` Å¡to je reÅ¡avanje analitiÄkih problema kroz mehaniÄke metode, ali Å¡toÅ¡ta-drugo je podloÅ¾no istom procesu. ÄŒak i stvari za koje ne bi pomislili da imaju tu ranjivost.
- NumeriÄke metode koje se Äesto primenjuju u HPC sistemima se mogu podeliti u sedam klasa poznatih kao `sedam patuljaka`

---
## Sedam patuljaka

1. Gusta linearna algebra
1. Retka linearna algebra
1. Spektralni metodi
1. Metodi N tela
1. Struktuirane mreÅ¾e
1. Nestruktuirane mreÅ¾e
1. Monte Karlo metode

---

## ProÅ¡irenje

- Ovo su, kada je podela napravljena, zaista bile glavne stvari zbog kojih se traÄ‡ilo HPC vreme, no vreme je donelo i par novih oblasti koje su bitne.

---

## ÄŒetiriâ€¦ dÅ¾ina? Gnoma?

1. Prolazak kroz grafove.
1. KonaÄne maÅ¡ine stanja.
1. KombinatoriÄka logika.
1. *StatistiÄke tehnike maÅ¡inskog uÄenja.*

---

## Klase problema i klase reÅ¡enja

- Dok klase problema donekle nameÄ‡u prirodu reÅ¡enja, klase reÅ¡enja odreÄ‘uju prirodu reÅ¡enja
- Klase problema su tipovi izazova sa kojima se susreÄ‡ete
- Klase reÅ¡enja su viÅ¡e kao alatke koje imate da te izazove nadmaÅ¡ite.

---

## Primeri generiÄkih klasa paralelnih algoritama

.center-table.small[

|          Klasa          |                                    Primer                                    |
|:-----------------------:|:----------------------------------------------------------------------------:|
|        Fork/join        |                                 Paralelni for                                |
| Zavadi pa vladaj.ref[1] |                           FFT, paralelno sortiranje                          |
|       Halo zamena       | Sistem konaÄnih elemenata odn. konaÄne razlike za differencijalne jednaÄine. |
|       Permutacije       |                            Kanonov algoritam, FFT                            |
|    Sramotno paralelna   |                                  Monte Carlo                                 |
|     MenadÅ¾er-Radnik     |                          Adaptivno rafinisanje meÅ¡-a                         |
| Zadaci protoka podataka |                              Pretraga po Å¡irini                              |

]

.footer.medium[
  1. Zavadi pa vladaj je naravno naÅ¡ prevod *Divide et impera* Å¡to Englezi prevode kao *Divide and conquer.* NaÅ¡ prevod je bolji, ali naÅ¾alost, manje ima smisla primenjen na algoritme.
] 

---

## Fork/join

![:scale 75%](img/fork-join-thread.png)

---

## Fork/join

- Ovo je najjednostavniji generiÄki algoritam za paralelizaciju.
- Vi ste ga koristili, konzervativno, barem hiljadu puta.
- Lepa stvar jeste u tome Å¡to radi za veliki broj problema.
- Fork znaÄi da jedinstvenu nit izvrÅ¡avanja cepamo na viÅ¡e niti, a join znaÄi da posle faze paralelnog izvrÅ¡avanja:
	- Re-sinhronizujemo ono Å¡to se izvrÅ¡ava.
	- Akumuliramo rezultate.
	- VraÄ‡amo se na jednostruko izvrÅ¡avanje.

- Fork/join nije samo OpenMP stvar, neÅ¡to vrlo sliÄno je moguÄ‡e na svakoj arhitekturi, a naroÄito prirodno na bilo Äemu sa deljenom memorijom.

---

## Zavadi pa vladaj

- Ideja zavadi-pa-vladaj algoritama jeste da se nekakav problem:
	- Podeli na manje delove
	- Rekurzivno se nastavi deljenje
	- Deljenje na manje delove ide sve dok se ne dostigne 'atomski' nivo operacije koji:
		- Ne moÅ¾e dalje da se deli
		- Komputaciono je trivijalan.
- Zavadi-pa-vladaj imaju smisla i u serijskoj implementaciji, ali zaista zablistaju u paralelnom sluÄaju, naroÄito u situaciji deljene memorije.
- Sistemi distribuirane memorije stvaraju problem u tome Å¡to kaÅ¡njenje u komunikaciji moÅ¾e da "pojede" prednosti koje zavadi-pa-vladaj donosi.

---
## Quicksort

- NajklasiÄniji primer zavadi-pa-vladaj algoritma je, naravno, quicksort algoritam za sortiranje.
- Quicksort je najbrÅ¾i algoritam za sortiranje u opÅ¡tem sluÄaju.
	- MoguÄ‡e je dokazati da nema brÅ¾eg kljuÄ-baziranog algoritma za sortiranje.
	- To i dalje ostavlja sisteme za sortiranje koji nisu bazirani na kljuÄu.
	- TakoÄ‘e, Quicksort je danas manje primenjen nego nekada zbog pragmatike upotrebe sortiranja u stvarnom kodu i frekvencije patoloÅ¡kih ulaza.
- Uprkos tome, i dalje se koristi (npr. .NET koristi QS podrazumevano, i zanimljiv je kao test paralelizacije)

---
## Quicksort

- Trebalo bi da ovo znate aliâ€¦
- Za neki niz odabrati nasumiÄno element koji Ä‡e biti stoÅ¾er (pivot), te onda napraviti dva pod-niza, elementi veÄ‡i od stoÅ¾era i elementi manji od stoÅ¾era.
- Ovaj proces izvrÅ¡iti rekurzivno na rezultujuÄ‡im pod-nizovima, sve dok se ne dobiju nizovi sa samo jednim elementom.
- ProÄitati sortirani niz sa leva na desno

---

## Quicksort

![:scale 60%](img/quicksort.png)

---

## Quicksort

.medium[
```c
private void SmartSort (List<int> list){
    SmartSort{lisl, 0, (list.Count - 1 > 0 ) ? list.Count - 1 : 0);
}

private void SmartSort(List<int> list, int lo, int hi){
    if (lo >= hi) return;
    int pivot = lo + (hi - lo) / 2;
    int Lemp;
    int storeLoc = lo;
    temp = list [hi];
    list[hi] = list [pivot];
    list[pivot] = temp;

    for (int i = lo; i < hi; i++) {
        if (list[i] < list [hi]) {
            temp = list[storeLoc];
            list[storeLoc] = list[i];
            list[i] = temp;
            storeLoc++;
        }
    }
    temp = list[storeLoc];
    list[storeLoc] = list[hi];
    list[hi] = temp;
    SmartSort (list, cmp, lo, storeLoc - 1);
    SmartSort (list, cmp, storeLoc + 1, hi);
    return;
}

```
]

---

## Paralelizacija Quicksort algoritma

- Momenat kada poÄne rekurzija, mi moÅ¾emo da algoritam paralelizujemo.
- Ako pogledate kod, videÄ‡ete da do samog kraja, svaka rekurzivna komponenta se izvrÅ¡ava u potpunoj paraleli.
- Nema izazova, pokrenemo rekurzivne komponente u paraleli i gotovi smo.
- Problem je u distribuiranim arhitekturama gde to Å¡to je neophodno da se podaci prebacuju sa mesta na mesto dramatiÄno smanjuje efikasnost.
- ReÅ¡enje? Quicksort modifikacija bazirana na uzorkovanju.

---

## Quicksort sa uzorkovanjem

- Za niz od N elemenata i P procesa se niz podeli na P jednakih segmenata veliÄine N/P. Svaki proces dobije jedan taj segment.
- Svaki proces lokalno QuickSort-uje svoj segment.
- RezultujuÄ‡e sortirane nizove mi uzorkujemo tj. uzimamo vrednosti iz njih na naÄin baziran na globalnoj veliÄini N i broju procesa P tako Å¡to ozimamo uzorke na svakoj Q-toj lokaciji poÄevÅ¡i od 0 gde je Q

<p>

$$ Q=\frac{N}{p^{2}} $$
  
</p>

- To znaÄi da su indeksi koje uzorkujemo oblika:

<p>

$$ 0, \frac{N}{p^{2}},\frac{2N}{p^{2}},...,(P-1)\frac{N}{p^{2}} $$
  
</p>

---
## Quicksort sa uzorkovanjem

- Sada kada imamo odabrane uzorke po svim procesima, oni se skupljaju u korenski proces i sortiraju sa sekvencijalnim QuickSort-om.
- Iz sortiranog skupa uzoraka se bira P-1 stoÅ¾erskih vrednosti koristeÄ‡i isti sistem uzorkovanja koji se koristio da se skup uzoraka napravi.
- Sve stoÅ¾erske vrednosti se poÅ¡alju svakom procesu.
- Svaki proces podeli svoj deo globalnog niza u P segmenata koristeÄ‡i P-1 soÅ¾erskih vrednosti.
- Nad rezultujuÄ‡im podacima se primeni MPI All-to-all operacija Äiji je rezultat da svaki od P procesa dobije sve primere jednog od P segmenata.
- Pristigle komponente segmenata se lokalno spoje i serijski QuickSort-uju.
- Sortirani nizovi se spoje u redosledu P-vrednosti. Algoritam je gotov.

---

## Quicksort sa uzorkovanjem

- Primetite da Äesto quick sort-ujemo serijski, lokalno.
- Ovo je Å¡ansa da joÅ¡ ubrzamo ovaj algoritam kroz hibridni pristup gde MPI koristimo da implementiramo ceo algoritam, a OpenMP da bi maksimalno ubrzali lokalne QuickSort-ove koji se prirodno paralelizuju na arhitekturama sa deljenom memorijom.

---

## MenadÅ¾er-radnik

- Ovo je opÅ¡ti obrazac paralelnog programiranja gde ima jedna nit odn. proces sa posebnim zaduÅ¾enjima zapoÄinjanja procesa i kontrole, i odreÄ‘eni broj usluÅ¾nih niti odn. procesa koji rade sav posao.
- Ovo je prirodno u interaktivnim aplikacijama gde, oÄigledno, zaista postoji posebna nit: `GUI nit`.
- MenadÅ¾er-radnik reÅ¡enja su naroÄito dobro prilagoÄ‘ena problemima gde ne znamo unapred Å¡ta Ä‡e se u svakom koraku algoritma desiti, no to dinamiÄki evoluira tokom rada.

---

## Deljena magistrala poruka

- Softverski Å¡ablon kojim se implementira menadÅ¾er-radnik jeste da postoji deljena magistrala podataka (message bus) koji niti/procesi dele na koji, tipiÄno, piÅ¡e korenska nit/proces, a koji osluÅ¡kuju usluÅ¾ne niti/procesi.
- Ako ste radili moderne tehnike distribuiranih serverskih sistema moÅ¾da ste naleteli na jednu implementaciju ovoga: Kafka.
- U lokalu se neÅ¡to sliÄno koristi: svaki GUI sistem je napravljen na sliÄan naÄin, naroÄito u Windows-u gde se zaista sve radi preko poruka.

---

## Sramotno paralelni algoritmi

- ZaÅ¡to sramotno?
- Pa, ideja je, da je toliko lako paralelizovati ove algoritme da vas je, kao HPC inÅ¾enjera, praktiÄno sramota.
- Renderovanje je klasiÄan primer.
- JoÅ¡, moÅ¾da, impresivniji primer je skoro bilo koji Monte Karlo algoritam.
- Monte Karlo algoritmi su takvi da, efektivno, pogaÄ‘aju nanovo i nanovo i nanovo i nanovo proizvodeÄ‡i rezultat koji, istina, nije taÄan, ali je svakom iteracijom pogaÄ‘anja sve taÄniji, tj. koriste nasumiÄno uzorkovanje da se asimptotski pribliÅ¾avaju taÄnom odgovoru.
- Ono Å¡to Äini veÄ‡inu Monte Karlo metoda sramotno paralelnim jeste to Å¡to iteracija 3039 nema niÅ¡ta zajedniÄko sa iteracijom 2929. Mogu se izvrÅ¡iti u bilo kom redosledu i ne komuniciraju.
- FantastiÄno.

---

## Primer Monte Karlo algoritma â€” raÄunanje broja Ï€

- Napravimo jediniÄni kvadrat 1x1.
- U tom kvadratu upiÅ¡emo jediniÄni krug.
- NasumiÄno generiÅ¡emo vrednosti unutar jediniÄnog kvadrata.
- Brojimo dve vrednosti: koliko smo taÄaka generisali i koliko od tih taÄaka je u krugu.
- Odnos izmeÄ‘u broja taÄaka u krugu i broja taÄaka ukupno Ä‡e asimptotski prilaziti Ï€/4.

---

## Kako paralelizovati ovaj algoritam?

- Lako!
- Sve Å¡to treba jeste da radimo ovu operaciju paralelno koliko god hoÄ‡emo i da na kraju toga skupimo sve brojeve kroz redukciju.
- Gotovo.
- Sramota vas je, zar ne?

---

## Halo komunikacija

- ÄŒesto imamo veoma paralelan sluÄaj gde svi procesni elementi rade istu stvar nad razliÄitim podacima skoro bez komunikacije.
- Skoro?
- Pa ako svaki procesni element ima svoj prostorno kompaktan domen gde radi svoju stvar jedini problem su granice tih prostorno kompaktnih domena.
- BuduÄ‡i da particija podataka odgovara particiji prostora, komunikacija je relevantna samo na tim slojevima izmeÄ‘u.
- Taj sloj se zove 'Halo' odn. 'Oreol' i ima osobinu dubine, tj. moÅ¾e biti dubok 1, 2, 3, itd. taÄaka.

---

## Primeri halo komunikacije

- TraÅ¾enje ivica nad velikom slikom (dubina od 0 do 7)
- ReÅ¡avanje parcijalnih diferencijalnih jednaÄina za advekciju.
- MnoÅ¾enje retkih matrica.

---

## Advekcija

- Advekcija je opÅ¡ti sluÄaj da se nekakvo skalarno polje f(x, t) Å¡iri ka smeru uveÄ‡ane vrednosti skalarne vrednosti x, brzinom v kroz vreme.
- Å ta?
- Mislite, na primer, provoÄ‘enje toplote.
- MatematiÄki, ovo je problem da za neku graniÄnu vrednost, reÅ¡imo parcijalnu diferencijalnu jednaÄinu:

<p>

$$ \frac{\partial f}{\partial t}=-v\frac{\partial f}{\partial x} $$
  
</p>

---

## Advekcija

- NumeriÄki, moÅ¾emo da reÅ¡imo preÄ‘aÅ¡nju jednaÄinu kroz metod konaÄnih razlika.
- Prvo, diskretizujemo i vreme (`n+1`) i prostor(`i`), vreme u korake simulacije `dt`, a prostor u uniformni meÅ¡.
- Onda se situacija svodi na reÅ¡avanje jednaÄine

<p>

$$ \frac{f_{i}^{n+1}-f_{i}^{n}}{dt}=-v\frac{f_{i+1}^{n}-f_{i}^{n}}{dx} $$
  
</p>

---

## Diskretizacija i parametri

- U preÄ‘aÅ¡njem `dx` i `dt` su samo veliÄine koraka diskretizacije, a `v` je parametar simulacije, tako da moÅ¾emo da uzmemo da te vrednosti imamo.
- TakoÄ‘e, ako imamo poÄetne vrednosti (Å¡to je neophodno za reÅ¡avanje diferencijalnih jednaÄina bilo koje vrednosti, buduÄ‡i da bez poÄetnih vrednosti diferencijalne jednaÄine u stvari definiÅ¡u porodice funkcija, a ne specifiÄne funkcije) jasno je da za momenat `n+1` sve Å¡to nam treba proistiÄe iz momenta `n`, tj. poznato je.

---

## KonaÄni oblik jednaÄine

<br><br>
<p>

$$ f_{i}^{n+1}=f_{i}^{n}-v\frac{dt}{dx}(\frac{f_{i}^{n+1}-f_{i}^{n}}{dx}) $$
  
</p>

---

#Komunikacija izmeÄ‘u procesa

- U sluÄaju advekcije komunikacija je trivijalna: samo nam treba preÄ‘aÅ¡nje stanje elementa odmah `desno` od nas i niÅ¡ta viÅ¡e. 
- To znaÄi da je transmisija podataka relativno jednostavna. 
- Halo je ovde dubok samo 1 i nesimetriÄan je.

---

## Permutacija

- Sistem permutacije jeste specijalizovana forma paralelizma na nivou podataka koji je karakteristiÄan i za halo komunikaciju
- Razlika jeste u tome Å¡to jednostavna halo komunikacija nije dovoljna, no je potrebno komunicirati kompleksnije na takav naÄin da su prave informacije na pravom mestu u pravom trenutku.
- Ovo moÅ¾e biti popriliÄno izazovno zato Å¡to zahteva da se, efektivno, radi na konstantno pomerajuÄ‡em modelu memorije.
- Primer je Kanonov algoritam za distribuirano mnoÅ¾enje gustih matrica.
	- Å½ao mi je.

---

## Kanonov algoritam

- Treba da pomnoÅ¾imo dve matrice i smestimo rezultat u treÄ‡u.
- Prvo, podelimo matrice na ravnomerne blokove koje odgovaraju jedne drugima, tj. i C i A i B imaju isti broj blokova.
- Onda te blokove podelimo izmeÄ‘u niti/procesa.

---

## Kanonov algoritam

![:scale 75%](img/k1.png)

---

## Kanonov algoritam

![:scale 75%](img/k2.png)

---

## Problem

- Ovde je teÅ¡koÄ‡a u tome Å¡to u procesu odgovornom za `C11`, recimo, imamo samo `A11` i `B11`. NiÅ¡ta drugo. 
- MoÅ¾emo da pomnoÅ¾imo podmatrice `A11` i `B11`, nema problema, ali Å¡ta onda?
- Naravno, mogli bi da drÅ¾imo celu matricu svuda, ali onda sve Å¡to imamo jeste model deljene memorije Å¡to je lepo aliâ€¦

---

## ReÅ¡enje

- ReÅ¡enje je komunikacija korak-po-korak.
- Ako opet pogledamo na onu jednaÄinu

<p>

$$ C_{11}=A_{10}B_{01}+A_{11}B_{11}+A_{12}B_{21}+A_{13}B_{31} \\ korak\quad 3:A_{10}B_{01} \\ korak\quad 0:A_{11}B_{11} \\ korak\quad 1:A_{12}B_{21} \\ korak\quad 2:A_{13}B_{31} $$
  
</p>

---

## ReÅ¡enje

- Podelili smo ono Å¡to treba da se uradi na korake (imamo i joÅ¡ jedan korak na kraju toga: redukciju, ali to nije problem) i valja primetiti da moÅ¾emo da taÄno vidimo na onoj slici podele kad nam treba koji komad podataka.

---

## Sekvenca zavisnosti od podataka

![:scale 75%](img/k3.png)

---

## Generalizacija

- Prirodno, ovo isto bi mogli da napravimo za bilo koju Ä‡eliju `C`
- Obrazac je apsolutno isti.
- Ostaje da vidimo Å¡ta taÄno razlikuje Å¡ta nam treba u koraku `N+1` u odnosu na korak `N`
- Odgovor: Treba nam Å¡ta je u `A` u Ä‡eliji odmah desno, a u `B` u Ä‡eliji odmah dole.
	- Uz `wraparound` kao da je matrica projektovana na povrÅ¡inu `torusa`, naravno.
- I to nam treba za svaki korak u svakom procesu.
- Drugim reÄima, uvek nam treba ista koliÄina podataka, samo koji su to podaci se menja.
- NaÄin na koji se to menja je predvidiv.

---

## Kanonov algoritam

- Kanonov algoritam je da, dakle, podelimo matricu kao Å¡to smo priÄali, a onda za svaki korak (koji zavisi od broja blokova na koje delimo matrice) izvrÅ¡imo mnoÅ¾enje, a onda Å¡iftujemo matricu `A` ulevo, a matricu `B` nagore.
- Onda samo ponovimo stvar.
- Drugim reÄima, permutacijom ukupnog skupa vrednosti mi Äinimo algoritam vrlo jednostavnim buduÄ‡i da uvek radi isto, samo sa drugim podacima.
- Dodatan bonus: `C` matrica se ne pomera, Å¡to znaÄi da Ä‡e na kraju svaki proces imati isti blok kao na poÄetku, samo sa skupljenim vrednostima u sebi koje samo treba `gather`-ovati.

---

## Kanonov algoritam

![:scale 50%](img/k4.png)

---

## Kanonov algoritam

![:scale 50%](img/k5.png)

---

## Model toka zadataka

- `Task dataflow` (model toka zadatka) je, na neki naÄin, maksimalno generiÄki model paralelizacije.
- Postave se podaci i veze izmeÄ‘u podataka, i onda se rezultujuÄ‡i graf particioniÅ¡e izmeÄ‘u procesa uz oÄekivanu sinhronizovanu komunikaciju tamo gde linija particije izmeÄ‘u procesa seÄe ivice grafa.
- Ovaj pristup se Äesto koristi kada je potrebno raditi maÅ¡insku paralelizaciju
	- `Breakthrough wanted`: Imati softverske alate koji paralelizuju umesto nas bi bilo zgodno.

- TakoÄ‘e se joÅ¡ viÅ¡e koristi za grafove usled prirodnog homomorfizma izmeÄ‘u njega i domena problema. 

--

class: center, middle, theend, hide-text
layout: false
background-image: url(../theend.gif)

</textarea>
	<script src="../remark-latest.min.js"></script>
	<script>
		// https://github.com/gnab/remark/issues/72
		        remark.macros.scale = function (percentage) {
		            var url = this;
		            return '<div class="center"><img src="'
		                 + url + '" style="width: ' + percentage + '" /></div>';
		        };
		        var slideshow = remark.create({
		                    highlightLanguage: 'python',
		                    // highlightStyle: 'obsidian',
		                    highlightStyle: 'github',
		                    highlightLines: true,
		                    countIncrementalSlides: false,
		                    navigation: {
		                      // Enable or disable navigating using scroll
		                      // Default: true
		                      // Alternatives: false
		                      scroll: false,
		
		                      //click: true,
		                    }
		                });
	</script>
	<script src="../mermaid.min.js"></script>
	<script>
		mermaid.initialize({startOnLoad:true});
	</script></body>

</html>