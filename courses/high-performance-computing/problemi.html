<!DOCTYPE html>
<html>

<head>
	<title>[High-performance computing (HPC)](/courses/#table-of-contents)</title>
	<meta charset="utf-8">
	<link rel="stylesheet" href="../remarkslides.css">
	<!-- MathJaxâ„¢ -->
	<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async>
	</script>
	<!-- mermaid dijagram -->
	<link rel="stylesheet2" href="../mermaid.min.css">
	<script>
		mermaid.initialize({startOnLoad:true});
	</script>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127734928-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		      function gtag(){dataLayer.push(arguments);}
		      gtag('js', new Date());
		
		      gtag('config', 'UA-127734928-1');
	</script>
	<!-- google analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		      ga('create', 'UA-127734928-1', 'auto');
		      ga('send', 'pageview');
	</script>
</head>

<body>
	<textarea id="source">class: center, middle

## [High-performance computing (HPC)](/courses/#table-of-contents)
### Problemi


.author[[dr. Milovan TomaÅ¡eviÄ‡](https://milovantomasevic.com/resume/)]

.small[[Fakulteta za informacijske Å¡tudije v Novem mestu (FIÅ )](https://www.fis.unm.si/en/)</br>![:scale 10%](../fis/fis.png) .small[ [ğŸŒâ™ milovan.tomasevic.fis.unm.si](http://milovan.tomasevic.fis.unm.si)</br> [ğŸ“§â™ milovan.tomasevic@fis.unm.si](mailto:milovan.tomasevic@fis.unm.si)]]



.created[08.03.2019 u 15:48]


---


class: center, middle, inverse

# ZaÅ¡to koristimo `HPC`? 

#### tipiÄni problemi `HPC`-a

---
layout: true

.section[[Domen problema](#sadrzaj)]

---

## `HPC` kao priznanje neuspeha

- Na jedan veoma stvaran naÄin, `HPC` je znak da smo se predali.
- Reformulacija problema nije radila.
- Lukavi algoritmi nisu radili.
- Sve Å¡to nam je ostalo jeste da napadnemo problem sa mnogo viÅ¡e resursa nego Å¡to je to normalno dostupno.
- `HPC` je, tako, zadnja linija odbrane kada se reÅ¡ava nekakav problem.

---

## `HPC` i ekonomija

- `HPC` je takoÄ‘e ograniÄen neoÄekivanim ekonomskim faktorima.
- Vi moÅ¾ete liÄni raÄunar namestiti da radi Å¡ta god Å¾elite: ako hoÄ‡ete da uposlite 100% CPU-a generiÅ¡uÄ‡i svetove kroz Dwarf Fortress niko se neÄ‡e buniti. U najgorem sluÅ¡aju troÅ¡ite malo dodatne struje.
- `HPC` klasteri i super-raÄunari su drugaÄiji: ozbiljne instalacije imaju troÅ¡kove izvrÅ¡avanja koji znaÄe da se svaki minut mora naplaÄ‡ivati.
- Stoga `HPC` se uglavnom koristi ili za projekte koje su interesantni vladama ili velikim kompanijama.

---

## Neke popularne primene

- Kriptanaliza
- NauÄna simulacija
    - Simulacija fluida
    - Simulacija plazme
    - Simulacija klime
    - SeizmoloÅ¡ki modeli
- StatistiÄka analiza ogromnih skupova podataka
- Problemi maÅ¡inskog uÄenja

---

## OgraniÄenje kursa

- Ovde mi prelazimo ove primene samo ovlaÅ¡ zato Å¡to, fundamentalno, svrha za koju se `HPC` primenjuje nije odgovornost `HPC` inÅ¾enjera. To je odgovornost domenskog eksperta. `HPC` se bavi time da su resursi za proraÄun dostupni.
- Kao deo ovog kursa od vas Ä‡e se traÅ¾iti da napiÅ¡ete seminarski rad o nekoj primeni zato Å¡to je zgodno da znate, makar okvirno, kako izgleda pravi problem ne bi li bili sposobniji da projektujete reÅ¡enja koja taj problem i njemu sliÄne reÅ¡avaju.

---

## Kriptanaliza

- Prvobitna primena raÄunara (te i, po definicji, `HPC`-a).
- Cela svrha kriptografije jeste da ne ostavi nikakav brz naÄin da se do podataka doÄ‘e bez nekog kljuÄnog elementa (kljuÄa, tipiÄno).
- Kriptanaliza, idealno, razbije algoritam za enkripciju tako da to ne vaÅ¾i.
- Danas su kriptografi mnogo veÅ¡tiji nego nekada i potpuno razbijeni algoritmi su retki. Alternativa jeste da se postigne parcijalno oslabljivanje gde se koliÄina nagaÄ‘anja i proraÄuna smanji donekle tako da (moÅ¾da?) doÄ‘e u domet najbrÅ¾ih super-raÄunara.
- MoÅ¾ete biti sigurni da negde u podrumima `NSA` zuje raÄunari koji se bave baÅ¡ ovim poslom.

---

## Kriptanalizaâ€”moguÄ‡i problem

- IstraÅ¾iti algoritam tipa opÅ¡teg sita polja brojeva (*general number field sieveâ€”GNFS*) i koristiti ga za faktorisanje poluprostih brojeva.
    - Poluprost (*semiprime*) je broj sa dva ne-trivijalna prosta faktora, npr. 2701 koji je 37 * 73.
- Ovo se onda lako moÅ¾e koristiti za razbijanje `RSA` enkripcije, tj. za ekstrakciju privatnog kljuÄa iz javnog kljuÄa.
- `GNFS` referentna implementacija je: https://sourceforge.net/projects/msieve/

---

## NauÄna simulacija

- Posmatrano sa veoma visokog nivoa apstrakcije, nauÄne simulacije su tipiÄno (mada ne nuÅ¾no) simulacije nekakvog fiziÄkog sistema koji je takav da je nemoguÄ‡e dobiti reÅ¡enje zatvorene forme no je neophodno raditi aproksimaciju i diskretizaciju.
- Recimo u komputacionoj dinamici fluida prostor se deli na komade (Ä‡elije) i specijalizovana verzija Navier-Stokes jednaÄina se reÅ¡ava za svaki taj komad u svakom kvantu vremena formirajuÄ‡i rezultat.

---

## Primer nauÄne simulacijeâ€”Problem n tela

- Problem `n`-tela je jedan od najpoznatijih i definitivno najstarijih problema u matematiÄkoj fizici.
- Imaju razne pod-formulacije koje sve objedinjuje sistem od n tela koji interaguju pod nekakvom silom no mi se ovde fokusiramo na vrlo jednostavnu, Njutnovsku verziju:
- Ako imamo `n` tela sa masama `m0â€¦n` i pozicijama `r0â€¦.n` koje variraju u odnosu na vreme `t`, kako Ä‡e ta tela da se ponaÅ¡aju pod efektom gravitacije.
- (Dalji deo predavanja delimiÄno baziran na materijalima Dr Rejmoda J. Spiterija za njegov kurs Parallel Programming for Scientific Computing drÅ¾an 2014 u Univerzitetu SaskaÄevana, a koji u bazirani na materijalima sa Berklija.) https://www.cs.usask.ca/~spiteri/CMPT851/notes/nBody.pdf

---

## Formulacija problema â€” ulazi

- U sistem ulaze:
    - PoÄetne pozicije svih tela
    - PoÄetne brzine svih tela
    - Mase svih tela
    - Vremenski parametri koji ukljuÄuju:
        - Koliko traje simulacija
        - Pod kojim koracima Å¾elimo izlaz

---

## Formulacija problemaâ€”izlazli

- Iz sistema izlazi:
    - Pozicija svakog tela za vremenske korake
    - Brzina svakog tela za vremenske korake

---

## Formulacija problemaâ€”pretpostavke

- VaÅ¾e Njutnovi zakoni kretanja i gravitacije
- Svi objekti su taÄkaste mase
- Svi objekti se mogu preklapati, tj. sudare modeliramo kao dva objekta na istom mestu.

---

## Notacija

- Neka je `n` broj tela (Äestica)
- Neka su mase `mi` sa `i` od `0` do `n-1`.
- Neka su pozicije `ri(t)` sa `i` od `0` do `n-1`, vektori.

---

## Fizika

- Onda je sila kojom Äestica j deluje na Äesticu i iznosi:

<p>

$$ f_{i,j}(t)=-\frac{Gm_{i}m_{j}}{||r_{i}(t)-r_{j}(t)||^{3}}(r_{i}(t)-r_{j}(t)) $$
  
</p>

- Gde vaÅ¾i:

<p>

$$ G=6.673\times10^{-11} \quad \frac{m}{(kg\cdot s^{2})} $$
  
</p>

---

## Fizika

- Ukupna sila na Äesticu Ä‡e onda biti:

<p>

$$ F_{i}(t)=\sum_{j=0, j\neq i}^{n-1}f_{i,j}(t) $$
  
</p>

---

## Fizika

- Å to moÅ¾emo da proÅ¡irimo u:

<p>

$$ F_{i}(t)=-Gm_{i}\sum_{j=0, j\neq i}^{n-1}\frac{m_{j}}{||r_{i}(t)-r_{j}(t)||^{3}}(r_{i}(t)-r_{j}(t)) $$
  
</p>

---

## Fizika

- KoristeÄ‡i Njutnov drugi zakon u vektorskoj formulaciji imamo onda:

<p>

$$ F_{i}(t)=m_{i}\ddot{r}_{i}(t) \quad za \quad i=0,1,...,n-1 $$
  
</p>

---

## Fizika

- Ovo nas na kraju dovede do sistema prostih diferencijalnih jednaÄina drugog reda oblika:

<p>

$$ \ddot{r}_{i}(t)= -G\sum_{j=0, j\neq i}^{n-1}\frac{m_{j}}{||r_{i}(t)-r_{j}(t)||^{3}}(r_{i}(t)-r_{j}(t)) $$
  
</p>

---

## Neke olakÅ¡ice

- Da bi nam Å¾ivot bio lakÅ¡i, u ovoj 'igraÄka' implementaciji radimo sa sledeÄ‡im ograniÄenjima:
    - Prostor je 2D i nije particionisan.
    - JednaÄinu integralimo koristeÄ‡i maksimalno jednostavnu Ojlerovu numeriÄku metodu koja gleda unapred.
    - Vremenski korak koji koristimo je konstantan.
- Ova ograniÄenja Äine ovo vrlo loÅ¡im algoritmom za n-tela, ali vrlo ilustrativnim.
- MoguÄ‡ zadatak: IstraÅ¾ivanje metoda za poveÄ‡anje preciznosti i brzine modela n tela Å¡to ukljuÄuje hijerarhijsko particionisanje prostora, dinamiÄko zaokruÅ¾ivanje na nulu, i adaptivni korak vremena.

---

## Ojlerova metoda?

- Prva i komiÄno najprostija metoda za numeriÄku integraciju diferencijalnih jednaÄina.
- Poznata je i kao najprostija Runge-Kuta metoda.
- Esencijalno, aproksimiramo nepoznatu krivu datu kroz njen izvod tako Å¡to je podelimo na male deliÄ‡e (koraci) u kojima se pretvaramo da je kriva linearna.

---

## Ojlerova metoda?

![:scale 75%](img/ojler.png)

---

## Ojlerova metoda?

- Ovo nije osobito dobar naÄin da se integrali diferencijalna jednaÄina.
- MoÅ¾e li bolje?
    - Nego Å¡ta.
    - Ali to je viÅ¡e posao za specijalistiÄki kod, o kome viÅ¡e kasnije.

---

## Gruba struktura algoritma

```c
foreach timestamp {
    foreach particle p[i]{
        calculate F_i(t);
        update r_i(t);
        update v_i(t);
    }
}
return (r, v);
 ```

---

## Gruba struktura proraÄuna Fi(t)

```c
foreach particle j{
    if(j != 1){
        dx = r[i].x - r[j].x;
        dy = r[i].y - r[j].y;
        d = sqrt(dx * dx + dy * dy);
        d3 = d*d*d;
        F[i].x -= G*m[i]*m[j]/d3*(r[i].x-r[j].x);
        F[i].y -= G*m[i]*m[j]/d3*(r[i].y-r[j].y);
    }
}
```

---

## Malo ubrzanje

- Postoji fundamentalna simetrija u problemu kojom moÅ¾emo da da prepolovimo broj proraÄuna
- Njutnov treÄ‡i zakon znaÄi da `fi,j(t) = -fj,i(t)`
- Ako znamo jednu, znamo i drugu, samo treba obrnuti znak.
- Kako da to uradimo lako?
- Najbolje je posmatrati matricu sile

---

## Matrica sile

<p>

$$ \begin{bmatrix}0 & f_{0,1}& f_{0,2}& ...& f_{0,n-1} \\-f_{0,1} & 0 & f_{1,2} &...&f_{1, n-1} \\... & ... & ... &.... &.... \\-f_{0,n-1} & -f_{1, n-1} & -f_{2,n-1} &.... &0 \end{bmatrix} $$
  
</p>

- Sada, sve Å¡to treba da uradimo jeste da napravimo skraÄ‡enu petlju nad gornjim odn. donjim trouglom matrice sile.

---

## Redukovani algoritam

```c
    foreach particle i{
        F_i(t) = 0;
    }
        foreach particle i{
            foreach particle j > i{
                F_i(t) += F_i,j(t);
                F_j(t) -= F_i,j(t);
            }
        }
```

---

## Dalji razvoj algoritma

- Kada imamo ukupne sile koje deluju na neku Äesticu, onda moÅ¾emo da kaÅ¾emo:

<p>

$$ a_{i}(t)= \ddot{r}_{i}(t)=\frac{F_{i}(t)}{m_{i}} $$
  
</p>

- Ovo je naÅ¡a diferencijalna jednaÄina koju hoÄ‡emo da integriÅ¡emo (dvaput) da bi dobili pomeraj tokom vremena.

---

## Pojednostavljenje jednaÄine

- Imamo Ojlerov metod koji smo pominjali ranije, ali on je za diferencijalne jednaÄine prvog reda oblika:

<p>

$$ \dot{y}(t)=f(t,y), \quad y(0)=y_{0}, \quad t>0 $$
  
</p>

- Mi imamo jednaÄinu drugog reda.
- SreÄ‡om, to se moÅ¾e popraviti: uvek je moguÄ‡e pretvoriti jednaÄinu m-tog reda u m jednaÄina prvog reda tako Å¡to se funkcija i njeni izvodi do m-1 tretiraju kao nepoznate.

---

## Pojednostavljenje jednaÄine

<p>

$$ \dot{r}_{i}(t)=v_{i}, \\ \dot{v}_{i}(t)=\frac{F_{i}(t)}{m_{i}} \quad i=0,1,2,...,n-1, \\r_{i}(0)=r_{i,0}, \quad v_{i}(0)=v_{i,0}, \quad i=0,1,2,...,n-1 $$
  
</p>

---

## Ojlerov metod primenjen na pojednostavljenu jednaÄinu

```c
r[i].x += dt*v[i].x;
r[i].y += dt*v[i].y;
v[i].x += dt*f[i].x/m[i];
v[i].y += dt*f[i].y/m[i];
```

---

## Pregledanje izvornog koda serijske implementacije

- Videti:
    - <a target="_blank" rel="noopener noreferrer" href="/courses/hpc-z5-openMPI/#table-of-contents"> â˜› Predavanja/`nbody_basic.c`</a>
    - <a target="_blank" rel="noopener noreferrer" href="/courses/hpc-z5-openMPI/#table-of-contents"> â˜› Predavanja/`nbody_red.c`</a>

---

## Problemi paralelizacije koda koristeÄ‡i model deljene memorije

- SuoÄeni smo sa klasiÄnim problemom: imamo kod koji radi serijski i hoÄ‡emo da ga ubrzamo.
- Ovo je najÄeÅ¡Ä‡e situacija u kojoj se `HPC` inÅ¾enjer naÄ‘e, domenski ekspert vam da nekakav kod i pozove vas da ga uÄinite brÅ¾im.
- Mnogo brÅ¾im.
- Jedino Å¡to se razlikuje od stvarnosti jeste Å¡to je Å¡ansa da Ä‡e kod biti uraÄ‘en u neÄemo pogodnijem za brzo prototipiziranje, kao Å¡to je Matlab ili, vrlo Äeto ovih dana, Python sa proÅ¡irenjima za nauÄno raÄunarstvo.
- U svakom sluÄaju, kako priÄ‡i ovakvom problemu?

---

## Fosterova metodologija

- 1995 dr Ian Foster koji se, moÅ¾emo da spekuliÅ¡emo, posvaÄ‘ao sa jednim previÅ¡e domenskim ekspertom, je predloÅ¾io opÅ¡tu metodologiju paralelizacije.
- Ova opÅ¡ta metodologija je baÅ¡ to. OpÅ¡ta. Nema gotovih reÅ¡ena u ovom poslu: Å¡ta moÅ¾e da se opiÅ¡e do tog nivoa je veÄ‡ odavno posao nekakvog automatizovanog algoritma.
- No, moÅ¾e da bude dobar potsetnik.

---

## Fosterova metodolgija

1. Particija (eng. *Partition*)
2. Komunikacija (eng. *Communication*)
3. Kombinacija (eng. *Agglomeration*)
4. Mapiranje (eng. *Mapping*)

---

## Particija

.lcol[

- Particija je podela osnovnog zadatka na pod-zadatke na najprimitivnijem nivou.
- Ovde nas ne zanima nikakvo ograniÄenje: samo lista stvari koje moramo da uradimo, a koje se na nivou apstrakcije na kome programiramo ne mogu dalje dekomponovati.
- Ako poÄinjemo od serijskog algoritma, ovaj posao se sastoji od brojanja.
]

.rcol[

![:scale 90%](img/problem.png)

]

---

## Komunikacija

.lcol[

![:scale 80%](img/kom.png)

]

.rcol[

- Kada imamo primitivne zadatke, sledeÄ‡i korak jeste da se ustanovi kakva je komunikacija izmeÄ‘u njih.
- U modelu deljene memorije to se naroÄito svodi na graf zavisnosti: koji podatak je potreban za raÄunanje kog podataka.
- Ako se setimo onog fibonaÄijevog niza od ranije, tu je baÅ¡ zavisnost izmeÄ‘u podataka bila deo posla koji nas je ograniÄavao.

]

---

## Kombinacija

.lcol[

- Ako su nam primitivni zadaci potpuno nezavisni, onda moÅ¾emo da ih kombinujemo kako god Å¾elimo.
- U praksi, biÄ‡e ograniÄenja, i ta ograniÄenja vode naÅ¡e kombinovanje primitivnih zadataka u celine pogodne za obradu.
]

.rcol[

![:scale 90%](img/kom2.png)

]

---

## Mapiranje

.lcol[

![:scale 90%](img/map.png)
]

.rcol[

- KonaÄan korak jeste da kombinovane celine podelimo u grupe koje Ä‡e se izvrÅ¡avati na procesnim elementima.
- Mapiranje je takoÄ‘e podloÅ¾no ograniÄenjima, specifiÄno, ograniÄenjima hardvera/arhitekture.

]

---

## Primena Fosterove metodologije na problem n tela

- Particija
    - Za svaku Äesticu (opÅ¡ti broj i) i korak vremena (opÅ¡ti broj k) sraÄunati

<p>

$$ F_{i}(t_{k-1}), \quad v_{i}(t_{k}), \quad r_{i}(t_{k}) $$
  
</p>

- Komunikacija

<p>

$$ Za\quad v_{i}(t_{k})\quad treba \\ v_{i}(t_{k-1}), \quad F_{i}(t_{k-1}), \quad r_{i}(t_{k-1}), \quad v_{j}(t_{k-1}) \\ Za\quad v_{i}(t_{k})\quad treba \\ r_{i}(t_{k-1}), \quad v_{i}(t_{k-1}) $$
  
</p>

---

## Primena Fosterove metodologije na problem n tela

- Kombinacija
    - VeÄ‡ina komunikacije ide po principu Äestica na Äesticu (i to najviÅ¡e ista Äestica)
    - To znaÄi da su nam kompozitni zadaci prirodno zadaci proraÄuna za individualnu Äesticu.
- Mapiranje
    - Imamo dve dimenzija mapiranja: broj Äestica i broj koraka.
    - Ojlerova metoda (kao Å¡to smo videli u analizi komunikacije) je fundamentalno sekvencijalna.
    - Ovo nameÄ‡e da paralelizam ima samo smisla ako rasporeÄ‘ujemo Äestice po procesima.

---

## PraktiÄno mapiranje

- To znaÄi da, u sluÄaju modela deljene memorije, na svaku sistemsku nit Å¾elimo da blokovski rasporedimo n/p Äestica gde je p broj sistemskih niti.
- ZaÅ¡to blokovski raspored? Zato Å¡to smanjuje keÅ¡ omaÅ¡aje a posao je homogen i moÅ¾e se lako razdeliti na ovaj naÄin.
- **Ovo vaÅ¾i samo ako ne koristimo redukciju da simetrijom smanjimo broj koraka.**

---

## Mapiranje u sluÄaju redukovanog algoritma

- TeÅ¡koÄ‡a je ovde u tome Å¡to nisu sada iteracije za svaku vrednost â€™iâ€™ iste. Niske vrednosti i su mnogo â€™skupljeâ€™ nego velike vrednosti i.
- Ovo znaÄi da Ä‡e u blokovskoj podeli da oni koji dobiju visoki blok zavrÅ¡iti ranije i morati da besposleno Äekaju niÅ¾e blokove.
- Ovaj scenario je, dakle, dobar za cikliÄnu distribuciju.
- Ali cikliÄna distribucija pati od visokog broja omaÅ¡aja u keÅ¡u.
- Pa Å¡ta baca viÅ¡e vremena? Ne moguÄ‡e je reÄ‡i apriori. Ovo je jedna od (mnogo) situacija u `HPC` svetu gde je profilisanje koda neophodno.
- Univerzalno reÅ¡enje `HPC`-a: idi i pogledaj.

---

## Paralelizacija neredukovanog algoritma

- Naivni pristup jeste da se uzmu dve unutarnje petlje algoritma (ona koja raÄuna sile i ona koja raÄuna pomeraje i brzine) i da se for-ovi paralelizuju u statiÄki raspored sa n/p po niti.
- Kako to izgleda?

```c
1: # pragma omp parallel for
2: for each particle i do
3:  Compute Fi(t).
4: end for
5: # pragma omp parallel for
6: for each particle i do
7:   Update ri(t) (and r`i(t) := vi(t)).
8: end for
```

---

## Potencijalni problemi?

- Potencijalan problem jeste situacija gde paralelne niti mogu da pristupaju istoj promenljivoj na naÄin koji otvara Å¡ansu za konflikt, tkzv. `race condition.`
- Zato, izmeÄ‘u ostalog, je komunikacija toliko bitna.
- Kako izgleda pseudo-kod prve petlje?

---

## Analiza prve petlje

.lcol[

```c
1: for each particle j != i do
2:    dx = r[i][x] - r[j][x];
3:    dy = r[i][y] - r[j][y];
4:    d = sqrt(dx * dx + dy * dy);
5:    d3 = d*d*d;
6:    F[i][x] -= G*m[i]*m[j]/d3*(r[i][x]-r[j][x]);
7:    F[i][y] -= G*m[i]*m[j]/d3*(r[i][y]-r[j][y]);
8: end for
```
]

.rcol[

- Za svaki `F[i]` moÅ¾e mu pristupiti samo jedna nit zbog prirode for konstrukta.
- Nit i Ä‡e pristupiti promenljivama `m[j]` i `r[j]` ali ove promenljive se samo Äitaju ovde, tako da smo bezbedni. 
- Samo pisanje stvara problem.
- Sve ostale promenljive su privremene i stoga, mogu biti privatne, te su bezbedne.

]

---

## Analiza druge petlje

.lcol[

- IskljuÄivo se piÅ¡e u promenljive `r[i]` i `v[i]` koje su ekskluzivne za odgovarajuÄ‡u nit.
- Sve ostalo se samo Äita.
- Nema moguÄ‡eg konflikta.
]

.rcol[

```c
1: r[i][x] += dt*v[i][x];
2: r[i][y] += dt*v[i][y];
3: v[i][x] += dt*f[i][x]/m[i];
4: v[i][y] += dt*f[i][y]/m[i];
```

]

---

## Redukovani algoritam

```c
1:    for each particle i do
2:        Fi(t) = 0;
3:    end for
4:    for each particle i do
5:        for each particle j > i do
6:            Fi(t) += fi,j(t);
7:            Fj(t) -= fi,j(t);
8:        end for
9:    end for
```

---

## Problemi

- Prva petlja nije problem. MoÅ¾e biti paralelizovana manje-viÅ¡e koliko god Å¾elimo.
- Druga petlja je problem
- Nit i piÅ¡e i u vrednost F[i] i u vrednost F[j] Å¡to znaÄi da je destruktivno preklapanje izmeÄ‘u niti apsolutno moguÄ‡e.
- Ako zamislimo trivijalan primer 4 Äestice i 2 niti uz blok-particiju onda raÄunamo silu na treÄ‡u Äesticu kao:

<p>

$$ F_{3}=f_{0,3}-f_{1,3}-f_{2,3} $$
  
</p>

- Ako, dalje, zamislimo da nit 0 raÄuna prva dva elementa, a nit 1 treÄ‡i, imamo konflikt. Rezultat zavisi od tajminga.

---

## Naivno reÅ¡enje

```c
    1:    for each particle i do
    2:        for each particle j > i do
    3:            # pragma omp critical {
    4:            Fi(t) += fi,j(t);
    5:            Fj(t) -= fi,j(t);
    6:            }
    7:        end for
    8:    end for
```
- Ovo radi, nema problema, ali pretvara naÅ¡ paralelni kod u serijski u kom sluÄaju, Å¡to smo se trudili?

---

## Malo manje naivno reÅ¡enje

```c
    1:    for each particle i do
    2:        for each particle j > i do
    3:            omp_set_lock(& locks[i])
    4:            Fi(t) += fi,j(t);
    5:            omp_unset_lock(& locks[i])
    6:            omp_set_lock(& locks[j])
    7:            Fj(t) -= fi,j(t);
    8:            omp_unset_lock(& locks[j])
    9:        end for
   10:    end for
```

- Ovo je mnogo bolje.
- Nemamo viÅ¡e jedan kritiÄni region koji blokira sve, nego samo tretiramo svaku Äesticu kao kritiÄni resurs.
- Bolje.
- Ali moÅ¾e joÅ¡ bolje.

---

## Lokalno Äuvanje

- Umesto da odmah raÄunamo sve sile i sabiramo ih i smeÅ¡tamo gde treba mi podelimo posao na dva:
    - RaÄunanje svih sila jedne niti koje smestimo u za nit lokalnu promenljivu.
    - Zbrajanje svih sila jedne Äestica tako Å¡to se zbrajaju vrednosti lokalnih promenljivih.
- Onda moÅ¾emo da paralelizujemo ove dve faze odvojeno sa taÄkom sinhronizacije izmeÄ‘u.

---

## Faza 1

```c
    1:    # pragma omp for
    2:    for each particle i do
    3:        Fi(t)=0 
    4:        for each particle j > i do
    5:            Floc,i(t) += fi,j(t);
    6:            Floc,j(t) -= fi,j(t);
    7:        end for
    8:    end for
```

- Ovo je isti kod kao i ranije, ali sada svaka nit ima svoje podatke o silama.
- To znaÄi da imamo na kraju malo traÄ‡enje memorije i gomilu polurezultata.
- Nema konflikta zato Å¡to jedino u Å¡ta se piÅ¡e je lokalno za nit.

---

## Faza 2

- Pretvaramo parcijalne u konaÄne rezultate.
- MoÅ¾emo o ovome da mislimo kao o ruÄnoj implementaciji operacije redukcije.
- Nema Å¡anse za konflikt jer i-ta nit je "vlasnik" i-te Äestice, a samo se u to piÅ¡e.

```c
    1:    # pragma omp for
    2:    for each particle i do
    3:        for each particle j > i do
    4:          Fi(t)+=Floc,p(t)
    5:        end for
    6:    end for
```

---

## Pregledanje izvornog koda OpenMP implementacije

- Videti:
    - <a target="_blank" rel="noopener noreferrer" href="/courses/hpc-z5-openMPI/#table-of-contents"> â˜› Predavanja/`omp_nbody_basic.c`</a>
    - <a target="_blank" rel="noopener noreferrer" href="/courses/hpc-z5-openMPI/#table-of-contents"> â˜› Predavanja/`omp_nbody_red.c`</a>

---

## Zadatak:

- Koliko je ovo brzo?
- Koji raspored zadataka (`static vs. cyclic`) proizvodi najbolje rezultate?

---

## OpenMPI paralelizacija

- Centralna ideja se ne razlikuje dramatiÄno u odnosu na OpenMP paralelizaciju.
- KljuÄan korak, kao i ranije, jeste kako individualne niti (koje su sada na razliÄitim maÅ¡inama) komuniciraju.
- Fundamentalna podela posla, opet, radi na nivou individualnih Äestica.
- Ako govorimo o ne-redukovanom algoritmu, onda komunikacija nastaje u okviru raÄunanja sile izmeÄ‘u i-te i j-te Äestice.
- To znaÄi da u svakom koraku, svaka Äestica zahteva poziciju svake druge Äestice (manje-viÅ¡e).
- Ovo je duÅ¡u dalo za `MPI_Allgather` operaciju.

---

## TehniÄki detalji struktura podataka

- Pod MPI umesto struct-a koristimo nizove elementarnih tipova zato Å¡to je komunikacija kroz elementarne tipove najbrÅ¾a.
- TakoÄ‘e, niz masa drÅ¾imo unapred kopiranim na sve instance zato Å¡to se mase nikad ne menjaju, a uvek su neophodne.
- Najbolji naÄin da razreÅ¡imo distribuciju podataka jeste kroz blokove pozicija za koje smo odgovorni (pozicije su ono Å¡to moramo da delimo iz koraka u korak) gde svaka nit pamti koji je njen blok kroz pokazivaÄe i fiksnu veliÄinu bloka.

---

## OpÅ¡ta struktura neredukovanog algoritma

```c
1: Get (and broadcast) input data.
2: for each timestep do
3:      for each local particle i-loc do
4:          Compute F-i-loc(t).
5.      end for
6:      for each local particle i-loc do
7:          Compute r-i-loc and v-i-loc
8:      end for
9:      Allgather r-i-loc to global array pos.
10: end for
```

---

## Pregledati kod

- <a target="_blank" rel="noopener noreferrer" href="/courses/hpc-z5-openMPI/#table-of-contents"> â˜› Predavanja/`mpi_nbody_basic.c`</a>

---

## MPI implementacija redukovanog algoritma

- Redukovani algoritam je jako problematiÄan za implementaciju u MPI okruÅ¾enju.
- Problem je kako proslediti prave informacije u pravom trenutku.
    - Svaki proces je odgovoran za neke Äestice, ali ne raÄuna sve sile za te Äestice. Neke sile Ä‡e raÄunati neko drugi.
    - To znaÄi da u svakom koraku moramo i da emitujemo naÅ¡e sile drugim procesima i da dobijemo sile od negde drugde samo da bi mogli da sraÄunamo sledeÄ‡u generaciju pozicija.
- Ovo je jako kompleksno, ali ako se implementira kako treba je Å¡ansa za istinski skalabilan i efikasan proces za raÄunanje proizvoljno velikih n-tela simulacija.

---

## Prstenska komunikaciona Å¡ema

- Prstenska komunikaciona Å¡ema je stari trik u komunikacionoj topologiji da se pojednostavi i regularizuje komunikacija.
- U praksi, svaki Ävor moÅ¾e da komunicira sa svakim drugim Ävorom na bilo koji naÄin, bilo kada, sa bilo kojim sadrÅ¾ajem.
- Ova sloboda znaÄi da niÅ¡ta ne moÅ¾e, a priori, da se kaÅ¾e o toj komunikaciji, ona nema osobine, i o njoj se ne moÅ¾e baÅ¡ puno rezonovati: suviÅ¡e je nedefinisano.
- Problem do koga ovo ultimativno dovede jeste da ne moÅ¾emo da optimizujemo komunikaciju zato Å¡to je ne razumemo.
- ReÅ¡enje jeste da se koriste obrasci gde ograniÄenja stvaraju strukturu.

---

## Prstenska komunikaciona Å¡ema

- U ovoj Å¡emi zamislimo sve MPI procese (njih q) u prstenu.
- Zatim ih poveÅ¾emo vodeÄ‡i raÄuna o ograniÄenju da `p`-ti proces samo komunicira sa procesima `p-1` i `p+1` ili, da bi bili neÅ¡to taÄniji, sa `(p - 1 + q) % q` i `(p+1) % q` (Å¡to se samo stara da se oÄuva prstenasta topologija.
- U okviru komunikacije vaÅ¾i pipeline princip: komunikacija je sinhronizovana i to tako da p prima podatke od `p-1` i Å¡alje ih `p+1`
- Posle `q` faza komunikacije, svi imaju sve podatke.

---

## Paralelizacija redukovanog algoritma kroz MPI

- Neka je broj Äestica dodeljenih jednom procesu l
- Onda u naÅ¡oj prstenskoj strukturi u svakoj fazi komunikacije svaki proces:
1. Å alje dalje l sila i l pozicija (svojih)
2. ProraÄuna silu izmeÄ‘u svojih Äestica i onih Äije pozicije primi.
3. Doda te sile svojim Äesticama i oduzme ih od sila koje dobije.

---

## Primer prstenskog stila komunikacije za n=4, p=2

.center-table.small[

|         **Vreme**        |  **Promenljiva** | **Proces0** | **Proces1** |
|:------------------------:|:----------------:|:-----------:|:-----------:|
|          PoÄetak         | lokalna_pozicija |    s0, s2   |    s1,s3    |
|          PoÄetak         |   lokalna_sila   |     0,0     |     0,0     |
|          PoÄetak         |   priv_pozicija  |    s0,s2    |    s1,s3    |
|          PoÄetak         |     priv_sila    |     0,0     |     0,0     |
|   Posle proraÄu na sila  | lokalna_pozicija |    s0,s2    |    s1,s3    |
|   Posle proraÄu na sila  |   lokalna_sila   |    f02,0    |    f13,0    |
|   Posle proraÄu na sila  |   priv_pozicija  |    s0,s2    |    s1,s3    |
|   Posle proraÄu na sila  |     priv_sila    |    0,-f02   |    0,-f13   |
| Posle prve komunik acije | lokalna_pozicija |    s0,s2    |    s1,s3    |
| Posle prve komunik acije |   lokalna_sila   |    f02,0    |    f13,0    |
| Posle prve komunik acije |   priv_pozicija  |    s1,s3    |    s0,s2    |
| Posle prve komunik acije |   priv_sila      |    0,-f13   |    0,-f02   |

]

---

## Primer prstenskog stila komunikacije za n=4, p=2 Vreme

.center-table.small[

|         **Vreme**        |  **Promenljiva** |        **Proces0**       |        **Proces1**        |
|:------------------------:|:----------------:|:------------------------:|:-------------------------:|
|   Posle proraÄuna sila   | lokalna_pozicija |          s0, s2          |           s1,s3           |
|   Posle proraÄuna sila   |   lokalna_sila   |      f01+f02+f03,f23     |         f12+f13,0         |
|   Posle proraÄuna sila   |   priv_pozicija  |           s1,s3          |           s0,s2           |
|   Posle proraÄuna sila   |     priv_sila    |     -f01,-f03-f13-f23    |         0,-f02-f12        |
| Posle druge komunikacije | lokalna_pozicija |           s0,s2          |           s1,s3           |
| Posle druge komunikacije |   lokalna_sila   |      f01+f02+f03,f23     |         f12+f13,0         |
| Posle druge komunikacije |   priv_pozicija  |           s0,s2          |           s1,s3           |
| Posle druge komunikacije |     priv_sila    |        0,-f02-f12        |     -f01,-f03-f13-f23     |
|   Posle proraÄuna sila   | lokalna_pozicija |           s0,s2          |           s1,s3           |
|   Posle proraÄuna sila   |   lokalna_sila   | f01+f02+f03,-f02-f12+f23 | -f01+f12+f13,-f03-f13-f23 |
|   Posle proraÄuna sila   |   priv_pozicija  |           s0,s2          |           s1,s3           |
|   Posle proraÄuna sila   |     priv_sila    |        0,-f02-f12        |     -f01,-f03-f13-f23     |

]

---

## TehniÄki detalji komunikacije

- Dovoljno je Äesto programirati ovako da se podaci istovremeno Å¡alju i rimaju da postoji funkcija koja nam Å¡tedi memoriju za takav tip komunikacije: `MPI_Sendrecv_replace` Äiji su parametri:
- ulazno izlazni bafer
- veliÄina bafera
- tip podataka
- odrediÅ¡te
- tag
- izvor
- tag
- kanal
- izlazni status

---

## MPI_Sendrecv_replace

- `MPI_Sendrecv_replace` istovremeno Å¡alje podatke u baferu i prima istu koliÄinu podataka.
- Kada se zavrÅ¡i, podaci koji su bili u baferu su odaslati dalje, a podaci koji su stigli su smeÅ¡teni u bafer.

---

## Pregledati kod

- <a target="_blank" rel="noopener noreferrer" href="/courses/hpc-z5-openMPI/#table-of-contents"> â˜› Predavanja/`mpi_nbody_red.c`</a>

---

## Ako Å¾elite joÅ¡ informacija

- Vrlo dobar pregled problema N tela se moÅ¾e naÄ‡i u Grop, Lusk, i Skjellum â€” Using MPI: Portable Parallel Programming with the Message Passing Interface u sekciji 5.2.
- ViÅ¡e o efikasnoj integraciji diferencijalnih jednaÄina ima u: William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. 2007. Numerical Recipes 3rd Edition: The Art of Scientific Computing (3 ed.). Cambridge University Press, New York, NY, USA. i to u poglavlju 17, stranica 899. NaroÄito obratite paÅ¾nju na sekcije 17.0 i 17.1.

--

class: center, middle, theend, hide-text
layout: false
background-image: url(../theend.gif)

</textarea>
	<script src="../remark-latest.min.js"></script>
	<script>
		// https://github.com/gnab/remark/issues/72
		        remark.macros.scale = function (percentage) {
		            var url = this;
		            return '<div class="center"><img src="'
		                 + url + '" style="width: ' + percentage + '" /></div>';
		        };
		        var slideshow = remark.create({
		                    highlightLanguage: 'python',
		                    // highlightStyle: 'obsidian',
		                    highlightStyle: 'github',
		                    highlightLines: true,
		                    countIncrementalSlides: false,
		                    navigation: {
		                      // Enable or disable navigating using scroll
		                      // Default: true
		                      // Alternatives: false
		                      scroll: false,
		
		                      //click: true,
		                    }
		                });
	</script>
	<script src="../mermaid.min.js"></script>
	<script>
		mermaid.initialize({startOnLoad:true});
	</script></body>

</html>